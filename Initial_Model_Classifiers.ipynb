{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, chdir\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify import NaiveBayesClassifier, MaxentClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Type               Restaurant_Name  \\\n",
      "0  Indian  Murugan Idli Shop, Singapore   \n",
      "1  Indian  Murugan Idli Shop, Singapore   \n",
      "2  Indian  Murugan Idli Shop, Singapore   \n",
      "\n",
      "                                        Review_Title  Sentiment  Rating  \\\n",
      "0                                  Soft hot sponges!          1      40   \n",
      "1                                     Excellent Idli          1      50   \n",
      "2  perfect for a weekend breakfast- if you love i...          1      40   \n",
      "\n",
      "  Review_Date                                     Review_Content  \n",
      "0   26-Oct-10  Home made idlies to the best! With varieties o...  \n",
      "1   17-Aug-10  I have never had such a soft idli's in my life...  \n",
      "2   14-Apr-10  one of the best places in Singapore for idlis ...  \n",
      "     Type                     Restaurant_Name  \\\n",
      "0  Indian  Muthu's Curry @ Dempsey, Singapore   \n",
      "1  Indian  Muthu's Curry @ Dempsey, Singapore   \n",
      "2  Indian  Muthu's Curry @ Dempsey, Singapore   \n",
      "\n",
      "                             Review_Title  Sentiment  Rating Review_Date  \\\n",
      "0  Bad Service + Good Food = Bad Outing!!         -1      10   21-Jun-15   \n",
      "1        Good taste, but poor hospitality         -1      20    6-Jun-15   \n",
      "2             So so Food with Bad Service         -1      20   14-Apr-15   \n",
      "\n",
      "                                      Review_Content  \n",
      "0  We are regular of the Muthu Curry joint, espec...  \n",
      "1  I visited this restaurant with my friends from...  \n",
      "2  Decided to try out Muthu's Curry. We had initi...  \n",
      "2923\n",
      "1386\n"
     ]
    }
   ],
   "source": [
    "# open the files for negative and positive sentiment mining\n",
    "ffile1 = open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\Trainset-pos.csv\",\"r\", encoding = 'utf-8',errors='ignore')\n",
    "ffile2 = open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\Trainset-neg.csv\",\"r\", encoding = 'utf-8',errors='ignore')\n",
    "\n",
    "df_pos = pd.read_csv(ffile1)\n",
    "df_neg = pd.read_csv(ffile2)\n",
    "ffile1.close()\n",
    "ffile2.close()\n",
    "\n",
    "print (df_pos.head(3))\n",
    "print (df_neg.head(3))\n",
    "\n",
    "print(len(df_pos))\n",
    "print(len(df_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET\n",
    "train_pos = [[x, 1] for x in df_pos[\"Review_Content\"]]\n",
    "train_neg = [[x, -1] for x in df_neg[\"Review_Content\"]]\n",
    "\n",
    "trainset = train_pos + train_neg\n",
    "train_tokenized = [[wt(x), c] for x,c in trainset]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "train_featureset = [(word_feats(d), c) for (d,c) in train_tokenized] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD SET\n",
    "ffile1 = open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\Train_Standardset-sentiment.csv\",\"r\", encoding = \"ISO-8859-1\",errors='ignore')\n",
    "df = pd.read_csv(ffile1, encoding = \"utf-8\")\n",
    "\n",
    "train_pos = [[row[\"Review_Content\"], 1] for idx, row in df.iterrows() if row[\"Sentiment\"]==\"positive\"]\n",
    "train_neg = [[row[\"Review_Content\"], -1] for idx, row in df.iterrows() if row[\"Sentiment\"]==\"negative\"]\n",
    "\n",
    "trainset_std = train_pos + train_neg\n",
    "train_tokenized_std = [[wt(x), c] for x,c in trainset_std]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "train_featureset_std = [(word_feats(d), c) for (d,c) in train_tokenized_std] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   worse = True               -1 : 1      =     26.6 : 1.0\n",
      "                     rip = True               -1 : 1      =     26.0 : 1.0\n",
      "                   worst = True               -1 : 1      =     25.0 : 1.0\n",
      "                    rude = True               -1 : 1      =     22.6 : 1.0\n",
      "                mediocre = True               -1 : 1      =     20.7 : 1.0\n",
      "                horrible = True               -1 : 1      =     19.8 : 1.0\n",
      "                 refused = True               -1 : 1      =     19.0 : 1.0\n",
      "                    poor = True               -1 : 1      =     18.1 : 1.0\n",
      "                terrible = True               -1 : 1      =     16.2 : 1.0\n",
      "                 ignored = True               -1 : 1      =     16.2 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>310</td>\n",
       "      <td>1076</td>\n",
       "      <td>1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2921</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>312</td>\n",
       "      <td>3997</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       310  1076  1386\n",
       "1          2  2921  2923\n",
       "All      312  3997  4309"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk for TRAINING SET\n",
    "classifier_nb = NaiveBayesClassifier.train(train_featureset)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb.show_most_informative_features(10)  # -10 to see positive\n",
    "\n",
    "## Preparing the data first \n",
    "train_nolab = [t[0] for t in trainset]\n",
    "train_lab = [t[1] for t in trainset]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_nolab)\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(train_vectors, train_lab)\n",
    "\n",
    "predNB = clf.predict(train_vectors)\n",
    "pred = list(predNB)\n",
    "cm1=pd.crosstab( pd.Series(train_lab), pd.Series(pred), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   worst = True               -1 : 1      =     38.3 : 1.0\n",
      "                   worse = True               -1 : 1      =     35.0 : 1.0\n",
      "               Excellent = True                1 : -1     =     25.4 : 1.0\n",
      "                    rude = True               -1 : 1      =     25.0 : 1.0\n",
      "                terrible = True               -1 : 1      =     20.9 : 1.0\n",
      "                mediocre = True               -1 : 1      =     19.3 : 1.0\n",
      "                    Ngee = True               -1 : 1      =     17.1 : 1.0\n",
      "                   awful = True               -1 : 1      =     17.1 : 1.0\n",
      "                    poor = True               -1 : 1      =     14.6 : 1.0\n",
      "                horrible = True               -1 : 1      =     14.4 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>249</td>\n",
       "      <td>1160</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2898</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>251</td>\n",
       "      <td>4058</td>\n",
       "      <td>4309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      -1     1   All\n",
       "actuals                 \n",
       "-1       249  1160  1409\n",
       "1          2  2898  2900\n",
       "All      251  4058  4309"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Naive Bayes Rule using nltk for STANDARD SET\n",
    "classifier_nb_std = NaiveBayesClassifier.train(train_featureset_std)\n",
    "#print(\"Accuracy :\" +str(accuracy(classifier_nb, test_featureset)))\n",
    "classifier_nb_std.show_most_informative_features(10)  \n",
    "\n",
    "## Preparing the data first \n",
    "train_nolab_std = [t[0] for t in trainset_std]\n",
    "train_lab_std = [t[1] for t in trainset_std]\n",
    "\n",
    "# Create your tf-idf function\n",
    "vectorizer_std = TfidfVectorizer()\n",
    "train_vectors_std = vectorizer_std.fit_transform(train_nolab_std)\n",
    "\n",
    "## train Naive Bayes Rule using sklearn\n",
    "clf_std = MultinomialNB().fit(train_vectors_std, train_lab_std)\n",
    "\n",
    "predNB_std = clf_std.predict(train_vectors_std)\n",
    "pred_std = list(predNB_std)\n",
    "cm2=pd.crosstab( pd.Series(train_lab_std), pd.Series(pred_std), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing the model\n",
    "## Preparing the data first as per usual\n",
    "ffile1 = open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\Testset-pos.csv\",\"r\", encoding = 'utf-8',errors='ignore')\n",
    "ffile2 = open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\Testset-neg.csv\",\"r\", encoding = 'utf-8',errors='ignore')\n",
    "df_pos = pd.read_csv(ffile1)\n",
    "df_neg = pd.read_csv(ffile2)\n",
    "ffile1.close()\n",
    "ffile2.close()\n",
    "test_pos = [[x, 1] for x in df_pos[\"Review_Content\"]]\n",
    "test_neg = [[x, -1] for x in df_neg[\"Review_Content\"]]\n",
    "testset = test_pos + test_neg\n",
    "test_nolab = [t[0] for t in testset]\n",
    "test_lab = [t[1] for t in testset]\n",
    "test_tokenized = [[wt(x), c] for x,c in testset]\n",
    "test_featureset = [(word_feats(d), c) for (d,c) in test_tokenized] \n",
    "test_nolab_tok = [t[0] for t in test_featureset]  # need to transform to predict\n",
    "\n",
    "test_vectors = vectorizer.transform(test_nolab)  \n",
    "test_vectors_std = vectorizer_std.transform(test_nolab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_nolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred     -1     1   All\n",
      "actuals                \n",
      "-1       43   556   599\n",
      "1         2  1251  1253\n",
      "All      45  1807  1852\n",
      "Accuracy is 0.699\n"
     ]
    }
   ],
   "source": [
    "# using split dataset\n",
    "predNB = clf.predict(test_vectors)\n",
    "predictions_nb = []\n",
    "for t in test_nolab_tok:\n",
    "    predictions_nb.append(classifier_nb.classify(t))\n",
    "cm3=pd.crosstab( pd.Series(test_lab), pd.Series(predNB), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm3)\n",
    "Accuracy = (cm3[1][1]+cm3[-1][-1])/(cm3[1][1]+(cm3[1][-1])+cm3[-1][1]+(cm3[-1][-1]))\n",
    "print (\"Accuracy is \" + str(round(Accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred     -1     1   All\n",
      "actuals                \n",
      "-1       72   527   599\n",
      "1         0  1253  1253\n",
      "All      72  1780  1852\n",
      "Accuracy is 0.715\n"
     ]
    }
   ],
   "source": [
    "# this is for the std Naive Bayes model using a larger and standard data set\n",
    "predNB_std = clf_std.predict(test_vectors_std)\n",
    "predictions_nb_std = []\n",
    "for t in test_nolab_tok:\n",
    "    predictions_nb_std.append(classifier_nb_std.classify(t))\n",
    "cm4=pd.crosstab( pd.Series(test_lab), pd.Series(predNB_std), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm4)\n",
    "Accuracy = (cm4[1][1]+cm4[-1][-1])/(cm4[1][1]+(cm4[1][-1])+cm4[-1][1]+(cm4[-1][-1]))\n",
    "print (\"Accuracy is \" + str(round(Accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.0 seconds ---\n",
      "0.6765658747300216\n",
      "74085\n"
     ]
    }
   ],
   "source": [
    "#Maximum Entropy Classifier (MaxEnt)\n",
    "import time\n",
    "stime = time.time()\n",
    "#classifier_me = MaxentClassifier.train(train_featureset_std, algorithm=\"IIS\", max_iter=5)\n",
    "# takes like 30 mins for 5 iterations\n",
    "print(\"--- %s seconds ---\" % (time.time() - stime))\n",
    "# IIS - improved iterative scaling - optimisation algorithm\n",
    "#pk.dump(classifier_me, open(fpath+\"\\\\Data\\\\maxent_std.pk\",\"wb\"))\n",
    "#pk.dump(classifier_me, open(fpath+\"\\\\Data\\\\maxent.pk\",\"wb\"))\n",
    "# pickle the classifier\n",
    "classifier_me = pk.load(open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\maxent_std.pk\",\"rb\"))\n",
    "#classifier_me = pk.load(open(fpath+\"\\\\Data\\\\maxent.pk\",\"rb\"))\n",
    "\n",
    "print(accuracy(classifier_me, test_featureset))\n",
    "\n",
    "wts = classifier_me.weights()\n",
    "print (len(wts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred     -1     1   All\n",
      "actuals                \n",
      "-1        1   598   599\n",
      "1         0  1253  1253\n",
      "All       1  1851  1852\n"
     ]
    }
   ],
   "source": [
    "pred_me = []\n",
    "classifier_me = pk.load(open(\"D:\\\\EBAC\\\\Semester 2\\\\New Media and Sentiment Mining\\\\Assignment\\\\maxent.pk\",\"rb\"))\n",
    "for t in test_nolab_tok:\n",
    "    pred_me.append(classifier_me.classify(t))\n",
    "\n",
    "cm5=pd.crosstab( pd.Series(test_lab), pd.Series(pred_me), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't NEG_like NEG_that NEG_place NEG_you NEG_keep NEG_calling NEG_awesome.\n"
     ]
    }
   ],
   "source": [
    "# Negative tagging\n",
    "def neg_tag(text):\n",
    "    transformed = re.sub(r\"\\b(?:never|nothing|nowhere|noone|none|not|haven't|hasn't|hasnt|hadn't|hadnt|can't|cant|couldn't|couldnt|shouldn't|shouldnt|won't|wont|wouldn't|wouldnt|don't|dont|doesn't|doesnt|didn't|didnt|isnt|isn't|aren't|arent|aint|ain't|hardly|seldom)\\b[\\w\\s]+[^\\w\\s]\", lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1NEG_\\2', match.group(0)), text, flags=re.IGNORECASE)\n",
    "    return(transformed)\n",
    "\n",
    "text = \"I don't like that place you keep calling awesome.\"\n",
    "print (neg_tag(text))\n",
    "\n",
    "# Create a training list which will now contain reviews with Negatively tagged words and their labels\n",
    "train_set_neg = []\n",
    "\n",
    "# Append elements to the list\n",
    "for doc in trainset:\n",
    "    trans = neg_tag(doc[0])\n",
    "    lab = doc[1]\n",
    "    train_set_neg.append([trans, lab])\n",
    "\n",
    "# Create a testing list which will now contain reviews with Negatively tagged words and their labels\n",
    "test_set_neg = []\n",
    "\n",
    "# Append elements to the list\n",
    "for doc in testset:\n",
    "    trans = neg_tag(doc[0])\n",
    "    lab = doc[1]\n",
    "    test_set_neg.append([trans, lab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train matrix shape (4309, 11779)\n",
      "Test matrix shape (1852, 11779)\n"
     ]
    }
   ],
   "source": [
    "# Using tf-idf as features for training\n",
    "# sklearn library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "vectorizer = TfidfVectorizer()  # tf-idf compared to term-document matrix\n",
    "\n",
    "# this is used below for training the SVM\n",
    "train_vectors = vectorizer.fit_transform(train_nolab)   # uses the UGC data set to classify the downloaded texts from Yelp\n",
    "test_vectors = vectorizer.transform(test_nolab)  \n",
    "#pk.dump(vectorizer, open(fpath+\"\\\\Data\\\\vectorise.pk\",\"wb\"))\n",
    "\n",
    "# Ascertain shape of the sparse matrix\n",
    "print (\"Train matrix shape \" + str(train_vectors.shape))\n",
    "print (\"Test matrix shape \" + str(test_vectors.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Features \n",
      "['admin', 'admiration', 'admiring', 'admit', 'admitt', 'admitted', 'admittedly', 'adore', 'adult', 'adults', 'advance', 'advanced', 'advantage', 'adventurous', 'advertise', 'advertised', 'advertisement', 'advertises', 'advertising', 'advertisings', 'advice', 'adviced', 'advices', 'advisable', 'advise', 'advised', 'adviser', 'advises', 'advising', 'advisor', 'advocates', 'afar', 'affair', 'affected', 'affectionados', 'affiliated', 'affirmative', 'affirmed', 'afford', 'affordable', 'aficionados', 'afield', 'afraid', 'africain', 'aft', 'after', 'afterall', 'afternoon', 'afternoonlocation', 'aftertaste']\n"
     ]
    }
   ],
   "source": [
    "print (\"Word Features \")\n",
    "print (vectorizer.get_feature_names()[500:550])\n",
    "termperdoc = vectorizer.inverse_transform(vectorizer.get_feature_names()[5000:5050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1     1   All\n",
      "actuals                 \n",
      "-1       385   214   599\n",
      "1        192  1061  1253\n",
      "All      577  1275  1852\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.67      0.65       577\n",
      "          1       0.85      0.83      0.84      1275\n",
      "\n",
      "avg / total       0.78      0.78      0.78      1852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier from sklearn\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=10000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "\n",
    "# Pickled model as it takes ahwile for generation\n",
    "classifier_svm = train_svm(train_vectors, train_lab)  # training the SVM model\n",
    "pk.dump(classifier_svm, open(\"classifier_svm.pk\",\"wb\"))\n",
    "#classifier_svm = pk.load(open(\"classifier_svm.pk\", \"rb\"))\n",
    "predSVM = classifier_svm.predict(test_vectors) \n",
    "pred_svm = list(predSVM)\n",
    "\n",
    "cm6=pd.crosstab( pd.Series(test_lab), pd.Series(pred_svm), rownames= ['actuals'], colnames=['pred'],margins=True)\n",
    "print (cm6)\n",
    "print (classification_report(pred_svm,  test_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |   -     |\n",
      "   |   1   1 |\n",
      "---+---------+\n",
      "-1 |<288>306 |\n",
      " 1 | 311<947>|\n",
      "---+---------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# k-nn classifier\n",
    "\n",
    "def train_knn(X, y, k, weight):\n",
    "    \"\"\"\n",
    "    Create and train the k-nearest neighbor.\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors = k, weights = weight, metric = 'cosine', algorithm = 'brute')\n",
    "    knn.fit(X, y)\n",
    "    return knn\n",
    "\n",
    "kn = train_knn(train_vectors, train_lab, 3, 'distance')# k=20; distance weights - by inverse of distance\n",
    "predKN = kn.predict(test_vectors)\n",
    "pred = list(predKN)\n",
    "cm = ConfusionMatrix(pred, test_lab)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |    -      |\n",
      "   |    1    1 |\n",
      "---+-----------+\n",
      "-1 | <303> 231 |\n",
      " 1 |  296<1022>|\n",
      "---+-----------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "def train_dtc(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Decision Tree Classifier.\n",
    "    \"\"\"\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X, y)\n",
    "    return dtc\n",
    "\n",
    "dt = train_dtc(train_vectors, train_lab)\n",
    "predDT = dt.predict(test_vectors)\n",
    "pred = list(predDT)\n",
    "cm = ConfusionMatrix(pred, test_lab)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 347  125]\n",
      " [ 252 1128]]\n",
      "0.7964362850971922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.58      0.74      0.65       472\n",
      "          1       0.90      0.82      0.86      1380\n",
      "\n",
      "avg / total       0.82      0.80      0.80      1852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ch21 = SelectKBest(chi2, k=5000)\n",
    "# Transform your training and testing datasets accordingly\n",
    "train_Kbest = ch21.fit_transform(train_vectors, train_lab)\n",
    "test_Kbest = ch21.transform(test_vectors)\n",
    "\n",
    "# Train your SVM with the k best selected features\n",
    "sv = train_svm(train_Kbest, train_lab)\n",
    "predSVM= sv.predict(test_Kbest)\n",
    "pred = list(predSVM)\n",
    "cm8 = confusion_matrix(pred, test_lab)\n",
    "print (cm8)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  85    6]\n",
      " [ 514 1247]]\n",
      "0.7192224622030238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.14      0.93      0.25        91\n",
      "          1       1.00      0.71      0.83      1761\n",
      "\n",
      "avg / total       0.95      0.72      0.80      1852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_Kbest, train_lab)\n",
    "predNB = clf.predict(test_Kbest)\n",
    "pred = list(predNB)\n",
    "cm9 = confusion_matrix(pred, test_lab)\n",
    "print (cm9)\n",
    "print (accuracy_score(pred, test_lab))\n",
    "print (classification_report(pred,  test_lab))\n",
    "\n",
    "# View the selected features\n",
    "selected_features = list(np.array(vectorizer.get_feature_names())[ch21.get_support()])\n",
    "#print (selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
